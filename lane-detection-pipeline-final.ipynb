{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, compute the camera calibration matrix and distortion coefficients given a set of chessboard images \n",
    "# (in the camera_cal folder in the repository)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx = 9\n",
    "ny = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((nx*ny,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    print(fname)\n",
    "    st = datetime.now()\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "        write_name = 'camera_cal/corners_found/'+str(idx)+'.jpg'\n",
    "        cv2.imwrite(write_name, img)\n",
    "    print('runtime: {}'.format(datetime.now()-st))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test undistortion on an image\n",
    "testfname = 'camera_cal/calibration3.jpg'\n",
    "img = cv2.imread(testfname)\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ret, mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k1, k2, p1, p2, k3. \n",
    "# k for radial distortion (curved lenses), p for tangential distortion (image plane not alingned with lens)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "cv2.imwrite('camera_cal/test_undist.jpg',dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"calibration_pickle.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10));\n",
    "ax1.imshow(img);\n",
    "ax1.set_title('Original Image', fontsize=30);\n",
    "ax2.imshow(dst);\n",
    "ax2.set_title('Undistorted Image', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next, for a series of test images (in the test_images folder in the repository):\n",
    "#\n",
    "#Apply the distortion correction to the raw image.\n",
    "#Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "#Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "#Detect lane pixels and fit to find lane boundary.\n",
    "#Determine curvature of the lane and vehicle position with respect to center.\n",
    "#Warp the detected lane boundaries back onto the original image.\n",
    "#Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_images/test3.jpg')\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply the distortion correction to the raw image.\n",
    "# inputs:\n",
    "#   img  -- input image\n",
    "#   mtx  -- camera matrix from calibrateCamera\n",
    "#   dist -- distortion coefficients from calibrateCamera\n",
    "def undistort(img, mtx, dist):\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "undist = undistort(image, mtx, dist)\n",
    "#cv2.imwrite('test_images/test5_undist.jpg',undist)\n",
    "undist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10));\n",
    "ax1.imshow(image);\n",
    "ax1.set_title('Original Image', fontsize=30);\n",
    "ax2.imshow(undist);\n",
    "ax2.set_title('Undistorted Image', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply Sobel along x or y axis to img.\n",
    "# Then takes an absolute value and apply thresholds.\n",
    "# Returns binary image.\n",
    "#   inputs\n",
    "#     img          -- input image\n",
    "#     orient       -- 'x' or 'y'\n",
    "#     kernel_size  -- sobel operator kernel size, in px\n",
    "#     thresholds   -- two values for low and high thresholds\n",
    "def sobel_abs_thresholds(img, orient='x', kernel_size=3, thresholds=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel / np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresholds[0]) & (scaled_sobel <= thresholds[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applies Sobel along x and y.\n",
    "# Computes the magnitude of the gradient and applies thresholds.\n",
    "# Returns binary image.\n",
    "#   inputs\n",
    "#     img          -- input image\n",
    "#     kernel_size  -- sobel operator kernel size, in px\n",
    "#     thresholds   -- two values for low and high thresholds\n",
    "def sobel_magnitude_thresholds(img, kernel_size=3, thresholds=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    abs_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel / np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresholds[0]) & (scaled_sobel <= thresholds[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applies Sobel along x and y, then computes the direction of the gradient for absolute sobel values.\n",
    "# Applies thresholds.\n",
    "# Returns binary image.\n",
    "#   inputs\n",
    "#     img          -- input image\n",
    "#     kernel_size  -- sobel operator kernel size, in px\n",
    "#     thresholds   -- two values for low and high thresholds\n",
    "def sobel_graddir_thresholds(img, kernel_size=3, thresholds=(0., np.pi/2)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    sobel_grad = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output = np.zeros_like(sobel_grad).astype(np.uint8)\n",
    "    binary_output[(sobel_grad >= thresholds[0]) & (sobel_grad <= thresholds[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts image to HLS color space.\n",
    "# Applies thresholds to the S-channel.\n",
    "# Returns binary image.\n",
    "#   inputs\n",
    "#     img          -- input image\n",
    "#     thresholds   -- two values for low and high thresholds\n",
    "def hls_s_thresholds(img, thresholds=(0, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS) \n",
    "    s = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(s)\n",
    "    binary_output[(s >= thresholds[0]) & (s <= thresholds[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thresholded_binary(image):\n",
    "    # sobel x\n",
    "    sx_kernel = 3\n",
    "    sx_thresh = (20, 100)\n",
    "    sx_binary = sobel_abs_thresholds(image, orient='x', kernel_size=sx_kernel, thresholds=sx_thresh)\n",
    "    # sobel y\n",
    "    sy_kernel = 3\n",
    "    sy_thresh = (30, 100)\n",
    "    sy_binary = sobel_abs_thresholds(image, orient='y', kernel_size=sy_kernel, thresholds=sy_thresh)\n",
    "    # sobel magnitude\n",
    "    smag_kernel = 5\n",
    "    smag_thresh = (30,100)\n",
    "    smag_binary = sobel_magnitude_thresholds(image, kernel_size=smag_kernel, thresholds=smag_thresh)\n",
    "    # sobel gradient direction\n",
    "    sgraddir_kernel = 7\n",
    "    sgraddir_thresh = (0.7, 1.3)\n",
    "    sgraddir_binary = sobel_graddir_thresholds(image, kernel_size=sgraddir_kernel, thresholds=sgraddir_thresh)\n",
    "    # HSV's S threshold\n",
    "    s_thresh = (170,255)\n",
    "    s_binary = hls_s_thresholds(image, thresholds=s_thresh)\n",
    "    # x gradient and S threshold\n",
    "    combined = np.zeros_like(sx_binary)\n",
    "    combined[(s_binary == 1) | (sx_binary == 1)] = 1\n",
    "    # x gradient and magnitude\n",
    "    combined0 = np.zeros_like(sx_binary)\n",
    "    combined0[(sx_binary == 1) & (smag_binary == 1)] = 1   \n",
    "    # y gradient and grad direction\n",
    "    combined3 = np.zeros_like(sy_binary)\n",
    "    combined3[(sy_binary == 1) & (sgraddir_binary == 1)] = 1    \n",
    "    # use previous combined, but add pixels where gradient magnitude and direction are activated\n",
    "    combined2 = np.copy(combined)\n",
    "    combined2[((smag_binary == 1) & (sgraddir_binary == 1))] = 1\n",
    "    # combined2 OR combined3\n",
    "    combined4 = np.copy(combined2)\n",
    "    combined4[combined3 == 1] = 1\n",
    "    # combined4 OR combined0\n",
    "    combined5 = np.copy(combined4)\n",
    "    combined5[combined0 == 1] = 1\n",
    "    return combined5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresholded_binary_image = thresholded_binary(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize combined\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10));\n",
    "ax1.imshow(image);\n",
    "ax1.set_title('Original Image', fontsize=30);\n",
    "ax2.imshow(thresholded_binary_image, cmap='gray');\n",
    "ax2.set_title('Thresholded Binary', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "copy = np.copy(thresholded_binary_image)\n",
    "color_copy = np.dstack((copy, copy, copy))\n",
    "src = np.float32([[85,670], \n",
    "                  [515,480], \n",
    "                  [765,480], \n",
    "                  [1195,670]])\n",
    "pts = np.array(src)\n",
    "cv2.fillPoly(color_copy, np.int_([pts]), (0,255,0));\n",
    "result = cv2.addWeighted(image, 1, color_copy, 0.3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize transform area\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10));\n",
    "ax1.imshow(copy, cmap='gray');\n",
    "ax1.set_title('Thresholded Image', fontsize=30);\n",
    "ax2.imshow(result);\n",
    "ax2.set_title('Perspective Transform', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Does perspective transform for the part of the road between lanes.\n",
    "# Takes undistorted image\n",
    "# Returns transfromed image, the matrix used to transform it and the matrix for inverse transform\n",
    "def perspective_transform(img, M=None, Minv=None):\n",
    "    imshape = img.shape\n",
    "    \n",
    "    if (M is None):\n",
    "        src = np.float32([[85,670], \n",
    "                          [515,480], \n",
    "                          [765,480], \n",
    "                          [1195,670]])\n",
    "        dst = np.float32([[imshape[1]*.05, imshape[0]*.95],\n",
    "                          [imshape[1]*.05, imshape[0]*.05],\n",
    "                          [imshape[1]*.95, imshape[0]*.05],\n",
    "                          [imshape[1]*.95, imshape[0]*.95]])\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    warped = cv2.warpPerspective(img, M, (imshape[1], imshape[0]), flags=cv2.INTER_LINEAR)\n",
    "    return warped, M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Does perspective transform for the part of the road between lanes.\n",
    "# Takes undistorted image\n",
    "# Returns transfromed image, the matrix used to transform it and the matrix for inverse transform\n",
    "def perspective_transform(img, M=None, Minv=None):\n",
    "    imshape = img.shape\n",
    "    \n",
    "    if (M is None):\n",
    "        src = np.float32([[85,670], \n",
    "                          [515,480], \n",
    "                          [765,480], \n",
    "                          [1195,670]])\n",
    "        dst = np.float32([[imshape[1]*.0, imshape[0]*1.],\n",
    "                          [imshape[1]*.0, imshape[0]*.0],\n",
    "                          [imshape[1]*1., imshape[0]*.0],\n",
    "                          [imshape[1]*1., imshape[0]*1.]])\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    warped = cv2.warpPerspective(img, M, (imshape[1], imshape[0]), flags=cv2.INTER_LINEAR)\n",
    "    return warped, M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_down_binary, M, Minv = perspective_transform(thresholded_binary_image, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10));\n",
    "ax1.imshow(thresholded_binary_image, cmap='gray');\n",
    "ax1.set_title('Thresholded Image', fontsize=30);\n",
    "ax2.imshow(top_down_binary, cmap='gray');\n",
    "ax2.set_title('Perspective Transform', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Detect lane pixels and fit to find lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    # class constants that are same for all instances\n",
    "    \n",
    "    # pct width of total image that one lane can occupy. used to decide on histograms\n",
    "    _pct_image_width_lane_width_max=0.1\n",
    "    # for the sliding window method -- height of the sliding window\n",
    "    _pct_image_height_slice=0.1\n",
    "    # Define conversions in x and y from pixels space to meters. depends on the end of pipeline 'top-down' image\n",
    "    #ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    _ym_per_pix = 3/130 # meters per pixel in y dimension. based on dashed line=3m\n",
    "    #xm_per_pix = 3.7/700 # meteres per pixel in x dimension. based on lane width = 3.7m\n",
    "    _xm_per_pix = 3.7/840 # meteres per pixel in x dimension\n",
    "    # history length for confirming detection\n",
    "    _n = 5\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self._detected = False\n",
    "        # number of last recent failed fits\n",
    "        self._failed_fits = 0\n",
    "        # x values of the last n fits of the line\n",
    "        self._recent_xfitted = []\n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self._bestx = None\n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self._best_fit = None\n",
    "        #polynomial coefficients for the most recent fit in px coordinates\n",
    "        self._current_fit_px = [np.array([False])]  \n",
    "        #polynomial coefficients for the most recent fit in m coordinates\n",
    "        self._current_fit_m = [np.array([False])]  \n",
    "        #radius of curvature of the line in pixels\n",
    "        self._radius_of_curvature = None \n",
    "        #radius of curvature of the line in meters\n",
    "        self._radius_of_curvature_m = None \n",
    "        #distance in px of vehicle center from the line\n",
    "        self._line_pos_px = None \n",
    "        #distance in m of vehicle center from the line\n",
    "        self._line_pos_m = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self._diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line image pixels\n",
    "        self._img_allx = None  \n",
    "        #y values for detected line image pixels\n",
    "        self._img_ally = None\n",
    "        #x values for detected sliding window pixels\n",
    "        self._histogram_allx = None  \n",
    "        #y values for detected sliding pixels\n",
    "        self._histogram_ally = None\n",
    "        #x values for fitted pixels\n",
    "        self._line_allx = None  \n",
    "        #y values for fitted pixels\n",
    "        self._line_ally = None\n",
    "        #devirative of fitted line wrt y at the bottom of top-down view, in px coordinates\n",
    "        self._y_deriv = None\n",
    "        \n",
    "    # find radius of curvature closest to the bottom of the image\n",
    "    def calc_radius_of_curvature(self):\n",
    "        # curvature in pixels\n",
    "        a = self._current_fit_px[0]\n",
    "        b = self._current_fit_px[1]\n",
    "        c = self._current_fit_px[2]\n",
    "        y_eval = np.max(self._line_ally)\n",
    "        self._radius_of_curvature = (1.0+(2.0*a*y_eval+b)**2)**1.5 / np.abs(2*a)\n",
    "        # curvature in meters\n",
    "        self._current_fit_m = np.polyfit(self._line_ally*self._ym_per_pix, self._line_allx*self._xm_per_pix, 2)\n",
    "        a = self._current_fit_m[0]\n",
    "        b = self._current_fit_m[1]\n",
    "        c = self._current_fit_m[2]\n",
    "        self._radius_of_curvature_m = ((1.0 + (2.0*a*y_eval + b)**2)**1.5) / np.abs(2*a)\n",
    "        # derivative of line wrt y at the bottom\n",
    "        self._y_deriv = 2*a*y_eval\n",
    "\n",
    "        \n",
    "    # given binary top-down view of lane pixels find possible left and right x values, in pixels\n",
    "    # using histogram method\n",
    "    # Used as static method. Does not change Line state.\n",
    "    #    inputs:\n",
    "    #       image                           -- binary image with top-down (perspective-transformed) view of lane lines. \n",
    "    #                                       -- assume x and y coordinates are reversed\n",
    "    #    outputs:\n",
    "    #        left_lane_x_px                 -- initial estimate for left lane x coordinate or None\n",
    "    #        right_lane_x_px                -- initial estimate for right lane x coordinate or None\n",
    "    def find_left_right_x(self, image):\n",
    "        histogram1 = np.sum(image, axis=0)\n",
    "        width = len(histogram1)\n",
    "        # find the most prominent peak in the histogram\n",
    "        imax1 = np.argmax(histogram1)\n",
    "        max1 = histogram1[imax1]\n",
    "        # remove the peak and pct_image_width_lane_width_max elements around it.\n",
    "        histogram2 = np.copy(histogram1)\n",
    "        nx = width*self._pct_image_width_lane_width_max\n",
    "        histogram2[imax1-int(nx/2.0) : imax1+int(nx/2.0)] = 0\n",
    "        # find second highest peak\n",
    "        imax2 = np.argmax(histogram2)\n",
    "        max2 = histogram2[imax2]\n",
    "        # remove the second peak and pct_image_width_lane_width_max elements around it.\n",
    "        histogram3 = np.copy(histogram2)\n",
    "        histogram3[imax2-int(nx/2.0) : imax2+int(nx/2.0)] = 0\n",
    "        # find third highest peak\n",
    "        imax3 = np.argmax(histogram3)\n",
    "        max3 = histogram3[imax3]\n",
    "\n",
    "        l = min(imax1, imax2)\n",
    "        r = max(imax1, imax2)\n",
    "\n",
    "        # decide what kind of situation we have\n",
    "        if max1/max3<1.5:\n",
    "            # inconsequential difference between topmost peak and the 'background'\n",
    "            return None, None\n",
    "        if max2/max3<1.5:\n",
    "            # inconsequential difference between second peak and the 'background'\n",
    "            return None if imax2==l else l, None if imax2==r else r\n",
    "        return l, r\n",
    "\n",
    "    # use sliding window to find the potential lane pixels.\n",
    "    # then fit second order polynomial to represent the line\n",
    "    #    inputs:\n",
    "    #       image                           -- binary image with top-down (perspective-transformed) view of lane lines. \n",
    "    #                                       -- assume x and y coordinates are reversed\n",
    "    #       initial_x                       -- x from which to start finding the line\n",
    "    def fit_from_x_on_image(self, image, initial_x):\n",
    "        (height, width) = image.shape # in the image operations x and y will be reversed\n",
    "        # sliding window points\n",
    "        nx = int(width*self._pct_image_width_lane_width_max)\n",
    "        ny = int(height*self._pct_image_height_slice)\n",
    "        y_points = np.arange(ny,height+1,ny)\n",
    "        x_points = np.zeros_like(y_points)\n",
    "        x_points[-1] = initial_x\n",
    "        imgcopy = np.zeros_like(image)\n",
    "        # sliding window loop\n",
    "        failed_window_points = 0\n",
    "        for i in range(len(y_points)-1,0,-1):\n",
    "            slice_y_bottom = y_points[i]\n",
    "            slice_y_top = slice_y_bottom - ny\n",
    "            slice_x_bottom = x_points[i]\n",
    "            imgslice = image[slice_y_top:slice_y_bottom,:]\n",
    "            ones = np.zeros_like(imgslice)\n",
    "            ones[:,slice_x_bottom-int(nx/2):slice_x_bottom+int(nx/2)] = 1\n",
    "            imgslice2 = np.bitwise_and(imgslice, ones)\n",
    "            imgcopy[slice_y_top:slice_y_bottom,:] = imgslice2\n",
    "            (y,x) = np.nonzero(imgslice2) # x and y are here in the 'opposite' order\n",
    "            if (len(set(y))>int(ny*.30)):\n",
    "                # looks like 'vertical' line segment\n",
    "                slice_x_top = np.mean(x)\n",
    "            else:\n",
    "                failed_window_points += 1\n",
    "                if self._detected:\n",
    "                    # if we fitted line successfully previously, use last fit for best estimate of top x in window\n",
    "                    slice_x_top = np.polyval(self._current_fit_px, slice_y_top)\n",
    "                else:\n",
    "                    slice_x_top = slice_x_bottom\n",
    "            x_points[i-1] = slice_x_top\n",
    "        # fit polymonial to x,y from sliding window loop\n",
    "        last = self._current_fit_px\n",
    "        self._current_fit_px = np.polyfit(y_points, x_points, 2)\n",
    "        self._diff = self._current_fit_px - last\n",
    "        self._line_ally = np.array(range(0,height))\n",
    "        self._line_allx = np.polyval(self._current_fit_px, self._line_ally)\n",
    "        # save/calculate additional data and y derivative at bottom (to test for parallel lines outside)\n",
    "        self._img_ally, self._img_allx = np.nonzero(imgcopy)\n",
    "        self.calc_radius_of_curvature() # also does y_deriv\n",
    "        self._line_pos_px = -(int(width/2) - self._line_allx[-1]) #distance in px of the line vs vehicle center\n",
    "        self._line_pos_m = self._line_pos_px * self._xm_per_pix   #distance in m of the line vs vehicle center \n",
    "        self._histogram_allx = x_points # remember sliding window points\n",
    "        self._histogram_ally = y_points\n",
    "        \n",
    "        # estimate confidence by looking at number of sliding window points that detect something like a line segment\n",
    "        # or whether line derivative wrt y is too big\n",
    "        if (failed_window_points > len(y_points)*0.70 or abs(self._y_deriv)>10.0 ):\n",
    "            self._failed_fits += 1\n",
    "        else:\n",
    "            self._failed_fits = 0\n",
    "\n",
    "        # draw extra annotations on temp result\n",
    "        imgcopy = cv2.cvtColor(imgcopy*255, cv2.COLOR_GRAY2BGR)\n",
    "        # plot points estimated from sliding histogram window\n",
    "        for p in zip(self._histogram_allx, self._histogram_ally):\n",
    "            cv2.circle(imgcopy, p, radius=6, color=(255,0,0), thickness=-1)\n",
    "        # plot fitted lines\n",
    "        cv2.polylines(imgcopy, \n",
    "                      np.int32([np.dstack([self._line_allx, self._line_ally])[0]]), \n",
    "                      isClosed=0, \n",
    "                      color=(0,0,255), thickness=5)\n",
    "        # update historical lists\n",
    "        self._recent_xfitted.append(self._line_allx[-1]) # bottom x from the fitted line\n",
    "        if len(self._recent_xfitted)>self._n:\n",
    "            self._recent_xfitted.pop(0)\n",
    "        self._bestx = np.mean(self._recent_xfitted) # average bottom x from last few fits\n",
    "        # average coefficients of the fit over last few fits\n",
    "        i = len(self._recent_xfitted)\n",
    "        if i==1:\n",
    "            self._best_fit = np.zeros_like(self._current_fit_px)\n",
    "        self._best_fit = (self._best_fit*(i-1) + self._current_fit_px) / float(i)\n",
    "        if i==self._n:\n",
    "            self._detected = True\n",
    "\n",
    "        return imgcopy\n",
    "    \n",
    "    \n",
    "    # go back to last good fit\n",
    "    #    inputs:\n",
    "    #       image                           -- binary image with top-down (perspective-transformed) view of lane lines. \n",
    "    #                                       -- assume x and y coordinates are reversed\n",
    "    #       initial_x                       -- x from which to start finding the line\n",
    "    def use_last_good_fit(self, image):\n",
    "        (height, width) = image.shape # in the image operations x and y will be reversed\n",
    "        \n",
    "        if len(self._recent_xfitted)<self._n:\n",
    "            # not enough history\n",
    "            return None\n",
    "        \n",
    "        # use last good coefficients\n",
    "        self._current_fit_px = self._best_fit\n",
    "\n",
    "        # sliding window points\n",
    "        nx = int(width*self._pct_image_width_lane_width_max)\n",
    "        ny = int(height*self._pct_image_height_slice)\n",
    "        y_points = np.arange(ny,height+1,ny)\n",
    "        x_points = np.zeros_like(y_points)\n",
    "        x_points[-1] = self._bestx\n",
    "        imgcopy = np.zeros_like(image)\n",
    "        # sliding window loop\n",
    "        for i in range(len(y_points)-1,0,-1):\n",
    "            slice_y_bottom = y_points[i]\n",
    "            slice_y_top = slice_y_bottom - ny\n",
    "            slice_x_bottom = x_points[i]\n",
    "            imgslice = image[slice_y_top:slice_y_bottom,:]\n",
    "            ones = np.zeros_like(imgslice)\n",
    "            ones[:,slice_x_bottom-int(nx/2):slice_x_bottom+int(nx/2)] = 1\n",
    "            imgslice2 = np.bitwise_and(imgslice, ones)\n",
    "            imgcopy[slice_y_top:slice_y_bottom,:] = imgslice2\n",
    "            (y,x) = np.nonzero(imgslice2) # x and y are here in the 'opposite' order\n",
    "            slice_x_top = np.mean(x)\n",
    "            slice_x_top = np.polyval(self._current_fit_px, slice_y_top)\n",
    "            x_points[i-1] = slice_x_top\n",
    "        \n",
    "        self._line_ally = np.array(range(0,height))\n",
    "        self._line_allx = np.polyval(self._current_fit_px, self._line_ally)\n",
    "        # save/calculate additional data and y derivative at bottom (to test for parallel lines outside)\n",
    "\n",
    "        self._img_ally, self._img_allx = np.nonzero(imgcopy)\n",
    "        self.calc_radius_of_curvature() # also does y_deriv\n",
    "        self._line_pos_px = -(int(width/2) - self._line_allx[-1]) #distance in px of the line vs vehicle center\n",
    "        self._line_pos_m = self._line_pos_px * self._xm_per_pix   #distance in m of the line vs vehicle center \n",
    "        self._histogram_allx = x_points # remember sliding window points\n",
    "        self._histogram_ally = y_points\n",
    "        \n",
    "        # just marking it to the outside as not 'great' fit\n",
    "        self._failed_fits += 1\n",
    "\n",
    "        # draw extra annotations on temp result\n",
    "        imgcopy = cv2.cvtColor(imgcopy*255, cv2.COLOR_GRAY2BGR)\n",
    "        # plot points estimated from sliding histogram window\n",
    "        for p in zip(self._histogram_allx, self._histogram_ally):\n",
    "            cv2.circle(imgcopy, p, radius=6, color=(255,0,0), thickness=-1)\n",
    "        # plot fitted lines\n",
    "        cv2.polylines(imgcopy, \n",
    "                      np.int32([np.dstack([self._line_allx, self._line_ally])[0]]), \n",
    "                      isClosed=0, \n",
    "                      color=(0,0,255), thickness=5)\n",
    "\n",
    "        return imgcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(height, width) = top_down_binary.shape\n",
    "# only use bottom half of the image for initial x detection\n",
    "# build histogram of lower half of the image, closer to the car -- lines should be more straight\n",
    "lx, rx = Line().find_left_right_x(top_down_binary[int(height/2):,:])\n",
    "lline = Line()\n",
    "rline = Line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lx, rx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class to combine the lane detection pipeline and keep track of both lines and produce output images\n",
    "class LaneDetector:\n",
    "    # initial number of images to be processed before detecting lane, assuming video\n",
    "    _initial_images_number = 5\n",
    "    # maximum difference of derivatives between two lines at the bottom\n",
    "    _max_deriv_diff = 5.0\n",
    "    # maximum lane width in meters\n",
    "    _max_lane_width_m = 4.4\n",
    "    # miminum lane width in meters\n",
    "    _min_lane_width_m = 1.7\n",
    "        \n",
    "    # takes distortion matrix and coefficients calibrated for the camera\n",
    "    def __init__(self, mtx, dist):\n",
    "        # undistortion matrix and coefficients\n",
    "        self._mtx = np.copy(mtx)\n",
    "        self._dist = np.copy(dist)\n",
    "        # objects to track left and right lines\n",
    "        self._lline = Line()\n",
    "        self._rline = Line()\n",
    "        # original image\n",
    "        self._original_image = None\n",
    "        # un-distorted image\n",
    "        self._undistorted_image = None\n",
    "        # thresholded binary combining different edge/contrast detection techniques\n",
    "        self._thresholded_binary_image = None\n",
    "        # road in front, perspective-transformed\n",
    "        self._top_down_binary_image = None\n",
    "        # perspective transform matrix and inverse\n",
    "        self._M, self._Minv = None, None\n",
    "        # binary image of road ahead with annotated fitted lines\n",
    "        self._top_down_binary_with_lines_image = None\n",
    "        # original undistorted image annotated with fitted lines\n",
    "        self._original_annotated_image = None\n",
    "        # image counter\n",
    "        self._image_number = 0\n",
    "        # number of bad sequential frames we encountered\n",
    "        self._bad_frames = 0\n",
    "        self._last_bad_frame = 0\n",
    "        \n",
    "    # put text on top-down binary view\n",
    "    def annotate_top_down_binary(self):\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        # curvature\n",
    "        if self._lline._detected:\n",
    "            lc = '{:,.2f}'.format(self._lline._radius_of_curvature)\n",
    "        else:\n",
    "            lc = 'NAN'\n",
    "        if self._rline._detected:\n",
    "            rc = '{:,.2f}'.format(self._rline._radius_of_curvature)\n",
    "        else:\n",
    "            rc = 'NAN'\n",
    "        s = 'curvature: Left {} px, Right {} px'.format(lc, rc)\n",
    "        cv2.putText(self._top_down_binary_with_lines_image, s, (350,100), font, fontScale=0.7, color=(0,255,0))\n",
    "        # line distance from car center\n",
    "        if self._lline._detected:\n",
    "            ld = '{:,.2f}'.format(self._lline._line_pos_px)\n",
    "        else:\n",
    "            ld = 'NAN'\n",
    "        if self._rline._detected:\n",
    "            rd = '{:,.2f}'.format(self._rline._line_pos_px)\n",
    "        else:\n",
    "            rd = 'NAN'\n",
    "        s2 = 'lane dist from center: Left {} px, Right {} px'.format(ld, rd)\n",
    "        cv2.putText(self._top_down_binary_with_lines_image, s2, (350,150), font, fontScale=0.7, color=(0,255,0))\n",
    "        s2 = 'derivs: Left {} px, Right {} px'.format(self._lline._y_deriv, self._rline._y_deriv)\n",
    "        cv2.putText(self._top_down_binary_with_lines_image, s2, (350,200), font, fontScale=0.7, color=(0,255,0))\n",
    "\n",
    "    # apply the lines and info text to the original undistorted image\n",
    "    def annotate_undistorted_image(self):\n",
    "        # draw area if both line detected\n",
    "        _color_warp = np.zeros_like(self._original_image)\n",
    "        if self._lline._detected and self._rline._detected:\n",
    "            # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "            _pts_left = np.array([np.transpose(np.vstack([self._lline._line_allx, self._lline._line_ally]))])\n",
    "            _pts_right = np.array([np.flipud(np.transpose(np.vstack([self._rline._line_allx, self._rline._line_ally])))])\n",
    "            _pts = np.hstack((_pts_left, _pts_right))\n",
    "            # Draw the lane onto the warped blank image\n",
    "            cv2.fillPoly(_color_warp, np.int_([_pts]), (0,255, 0))\n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        _newwarp = cv2.warpPerspective(_color_warp, self._Minv, (width,height)) \n",
    "        # Combine the result with the original image\n",
    "        self._original_annotated_image = cv2.addWeighted(self._undistorted_image, 1, _newwarp, 0.3, 0)\n",
    "\n",
    "        # draw left line if detected\n",
    "        _color_warp = np.zeros_like(self._original_image)\n",
    "        if (self._lline._detected):\n",
    "            if (self._lline._failed_fits > 0):\n",
    "                color = (255,0,0)\n",
    "            else:\n",
    "                color = (0,128,128)\n",
    "            cv2.polylines(_color_warp, \n",
    "                          np.int32([np.dstack([self._lline._line_allx, self._lline._line_ally])[0]]), \n",
    "                          isClosed=0, \n",
    "                          color=color, thickness=60)\n",
    "        # draw right line if detected\n",
    "        if (self._rline._detected):\n",
    "            if (self._rline._failed_fits > 0):\n",
    "                color = (255,0,0)\n",
    "            else:\n",
    "                color = (0,128,128)\n",
    "            cv2.polylines(_color_warp, \n",
    "                          np.int32([np.dstack([self._rline._line_allx, self._rline._line_ally])[0]]), \n",
    "                          isClosed=0, \n",
    "                          color=color, thickness=60)\n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        _newwarp = cv2.warpPerspective(_color_warp, self._Minv, (width,height)) \n",
    "        # Combine the result with the original image\n",
    "        self._original_annotated_image = cv2.addWeighted(self._original_annotated_image, 1, _newwarp, 1.0, 0)\n",
    "        \n",
    "        \n",
    "        # add text details\n",
    "        _overlay = np.zeros_like(self._original_image)\n",
    "        cv2.rectangle(_overlay, (250,60), (1100,200), (255,255,255), -1)\n",
    "        self._original_annotated_image = cv2.addWeighted(self._original_annotated_image, 1, _overlay, 0.8, 0)\n",
    "        font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "        \n",
    "        # curvature\n",
    "        if self._lline._detected:\n",
    "            if abs(self._lline._radius_of_curvature_m) < 10000:\n",
    "                lc = '{:,.0f}m'.format(self._lline._radius_of_curvature_m)\n",
    "            else:\n",
    "                lc = 'STRAIGHT'\n",
    "        else:\n",
    "            lc = 'NAN'\n",
    "        if self._rline._detected:\n",
    "            if abs(self._rline._radius_of_curvature_m) < 10000:\n",
    "                rc = '{:,.0f}m'.format(self._rline._radius_of_curvature_m)\n",
    "            else:\n",
    "                rc = 'STRAIGHT'\n",
    "        else:\n",
    "            rc = 'NAN'\n",
    "        s = 'curvature: Left {}, Right {}'.format(lc, rc)\n",
    "        cv2.putText(self._original_annotated_image, s, (300,100), \n",
    "                    font, fontScale=0.7, color=(0,0,0), lineType=cv2.LINE_AA)\n",
    "        \n",
    "        # line distance from car center\n",
    "        if self._lline._detected:\n",
    "            ld = '{:,.2f}m'.format(self._lline._line_pos_m)\n",
    "        else:\n",
    "            ld = 'NAN'\n",
    "        if self._rline._detected:\n",
    "            rd = '{:,.2f}m'.format(self._rline._line_pos_m)\n",
    "        else:\n",
    "            rd = 'NAN'\n",
    "        s2 = 'lane distance from car center: Left {}, Right {}'.format(ld, rd)\n",
    "        cv2.putText(self._original_annotated_image, s2, (300,130), \n",
    "                    font, fontScale=0.7, color=(0,0,0), lineType=cv2.LINE_AA)\n",
    "\n",
    "        if self._lline._detected and self._rline._detected:\n",
    "            s3 = 'car off center by: {:,.2f}m'.format(self._lline._line_pos_m+self._rline._line_pos_m)\n",
    "        else:\n",
    "            s3 = 'car off center by: UNDEFINED'\n",
    "        cv2.putText(self._original_annotated_image, s3, (300,160), \n",
    "                    font, fontScale=0.7, color=(0,0,0), lineType=cv2.LINE_AA)\n",
    "        \n",
    "    def create_diagnostic_view(self):\n",
    "        (height, width, _) = self._original_image.shape\n",
    "        self._diagnostic_view = np.zeros((height*2, width, 3), dtype=np.uint8)\n",
    "        self._diagnostic_view[0:height, 0:width] = self._original_annotated_image\n",
    "        rh = int(height/2)\n",
    "        rw = int(width/2)\n",
    "        # distorted original image\n",
    "        self._diagnostic_view[height:(height+rh), 0:(rw)] = cv2.resize(self._original_image, (rw,rh), interpolation=cv2.INTER_AREA) \n",
    "        # thresholded binary\n",
    "        img = cv2.cvtColor(self._thresholded_binary_image*255, cv2.COLOR_GRAY2BGR)\n",
    "        self._diagnostic_view[height:(height+rh), rw:(2*rw)] = cv2.resize(img, (rw,rh), interpolation=cv2.INTER_AREA) \n",
    "        # perspective-transformed binary\n",
    "        img = cv2.cvtColor(self._top_down_binary_image*255, cv2.COLOR_GRAY2BGR)\n",
    "        self._diagnostic_view[(height+rh):(height+2*rh), 0:(rw)] = cv2.resize(img, (rw,rh), interpolation=cv2.INTER_AREA) \n",
    "        # annotated binary\n",
    "        self._diagnostic_view[(height+rh):(height+2*rh), rw:(2*rw)] = cv2.resize(self._top_down_binary_with_lines_image, (rw,rh), interpolation=cv2.INTER_AREA) \n",
    "        \n",
    "        \n",
    "    def process_image(self, image, initial_images_number=1, return_diagnostic_views=True):\n",
    "        self._original_image = np.copy(image)\n",
    "        self._image_number += 1\n",
    "        (height, width, _) = self._original_image.shape\n",
    "        # un-distort image\n",
    "        self._undistorted_image = undistort(self._original_image, self._mtx, self._dist)\n",
    "        # produce thresholded binary\n",
    "        self._thresholded_binary_image = thresholded_binary(self._undistorted_image)\n",
    "        # perspective transform of the road in front\n",
    "        self._top_down_binary_image, self._M, self._Minv = perspective_transform(self._thresholded_binary_image, \n",
    "                                                                                 self._M, self._Minv)\n",
    "\n",
    "        # initial detection or detection after unsuccessful fits in preceding frames\n",
    "        lx, rx = None, None\n",
    "        if (self._image_number < self._initial_images_number or self._bad_frames > 5):\n",
    "            # only use bottom half of the image for initial x detection using histogram method\n",
    "            # build histogram of lower half of the image, closer to the car -- lines should be more straight\n",
    "            lx, rx = Line().find_left_right_x(self._top_down_binary_image[int(height/2):,:])\n",
    "            self._bad_frames = 0\n",
    "        else:\n",
    "            _rx = None\n",
    "            if (not self._lline._detected or self._lline._failed_fits>0):\n",
    "                # problems with left line detection in previous iterations. let's use histogram method to find it afresh\n",
    "                lx, _rx = Line().find_left_right_x(self._top_down_binary_image[int(height/2):,:])\n",
    "            if (not self._rline._detected or self._rline._failed_fits>0):\n",
    "                # problems with right line detection in previous iterations. let's use histogram method to find it afresh\n",
    "                if _rx is not None:\n",
    "                    rx = _rx\n",
    "                else:\n",
    "                    lx_, rx = Line().find_left_right_x(self._top_down_binary_image[int(height/2):,:])\n",
    "        # if initial detections or trying to detect the lines after unseccessful attempts\n",
    "        # did not result in some estimate of x for left or right lines, use the best x estimates found so far\n",
    "        if lx is None and self._lline._detected:\n",
    "            lx = self._lline._bestx\n",
    "        if rx is None and self._rline._detected:\n",
    "            rx = self._rline._bestx\n",
    "            \n",
    "        # fit the lines from best x we found so far\n",
    "        # updates _detected attribute\n",
    "        if lx is not None:\n",
    "            l_imgcopy = self._lline.fit_from_x_on_image(self._top_down_binary_image, lx)\n",
    "        if rx is not None:\n",
    "            r_imgcopy = self._rline.fit_from_x_on_image(self._top_down_binary_image, rx)\n",
    "\n",
    "        # test if lines are parallel\n",
    "        if self._lline._detected and self._rline._detected \\\n",
    "                and abs(self._lline._y_deriv - self._rline._y_deriv) > self._max_deriv_diff:\n",
    "            # high chance of wrong fit of either line or both\n",
    "            print('frame {}: NOT PARALLEL'.format(self._image_number))\n",
    "            if self._last_bad_frame+1 == self._image_number:\n",
    "                self._bad_frames += 1\n",
    "                self._last_bad_frame = self._image_number\n",
    "            else:\n",
    "                self._last_bad_frame = 0\n",
    "                self._bad_frames = 0\n",
    "            l_imgcopy = self._lline.use_last_good_fit(self._top_down_binary_image)\n",
    "            r_imgcopy = self._rline.use_last_good_fit(self._top_down_binary_image)\n",
    "            #self._lline._detected = False\n",
    "            #self._rline._detected = False\n",
    "        # test if lines are about the right distance, left is left and right is right\n",
    "        if self._lline._detected and self._rline._detected \\\n",
    "                and (abs(detector._rline._line_pos_m - detector._lline._line_pos_m) > self._max_lane_width_m\n",
    "                     or abs(detector._rline._line_pos_m - detector._lline._line_pos_m) < self._min_lane_width_m\n",
    "                     or detector._rline._line_pos_m < detector._lline._line_pos_m\n",
    "                    ):\n",
    "            # high chance of wrong fit of either line or both\n",
    "            print('frame {}: WRONG DISTANCE {}, {}, {}, {}'.format(self._image_number, lx, rx, detector._lline._line_pos_m, detector._rline._line_pos_m))\n",
    "            if self._last_bad_frame+1 == self._image_number:\n",
    "                self._bad_frames += 1\n",
    "                self._last_bad_frame = self._image_number\n",
    "            else:\n",
    "                self._last_bad_frame = 0\n",
    "                self._bad_frames = 0\n",
    "            l_imgcopy = self._lline.use_last_good_fit(self._top_down_binary_image)\n",
    "            r_imgcopy = self._rline.use_last_good_fit(self._top_down_binary_image)\n",
    "            #self._lline._detected = False\n",
    "            #self._rline._detected = False\n",
    "\n",
    "        # combine both lines info in the top-down image\n",
    "        if self._lline._detected and self._rline._detected:\n",
    "            self._top_down_binary_with_lines_image = np.bitwise_or(l_imgcopy, r_imgcopy)\n",
    "        elif not self._lline._detected and self._rline._detected:\n",
    "            self._top_down_binary_with_lines_image = r_imgcopy\n",
    "        elif self._lline._detected and not self._rline._detected:\n",
    "            self._top_down_binary_with_lines_image = l_imgcopy\n",
    "        else:\n",
    "            self._top_down_binary_with_lines_image = cv2.cvtColor(self._top_down_binary_image*255, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        self.annotate_top_down_binary()\n",
    "\n",
    "        self.annotate_undistorted_image()\n",
    "                \n",
    "        if (not return_diagnostic_views):\n",
    "            return self._original_annotated_image\n",
    "        else:\n",
    "            self.create_diagnostic_view()\n",
    "            return self._diagnostic_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"calibration_pickle.p\", mode='rb') as f:\n",
    "    dist_pickle = pickle.load(f)\n",
    "detector = LaneDetector(dist_pickle['mtx'], dist_pickle['dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_images/test2.jpg')\n",
    "import cProfile\n",
    "cProfile.run('detector.process_image(image)','profstat')\n",
    "import pstats\n",
    "p = pstats.Stats('profstat')\n",
    "p.sort_stats('cumulative').print_stats(20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(detector._diagnostic_view);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = LaneDetector(dist_pickle['mtx'], dist_pickle['dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_images/test1.jpg')\n",
    "\n",
    "detector.process_image(image)\n",
    "\n",
    "# Visualize\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20,10));\n",
    "plt.tight_layout()\n",
    "ax1.imshow(detector._undistorted_image);\n",
    "ax1.set_title('Undistorted Image', fontsize=30);\n",
    "ax2.imshow(detector._top_down_binary_image, cmap='gray');\n",
    "ax2.set_title('Top down binary', fontsize=30);\n",
    "ax3.imshow(detector._top_down_binary_with_lines_image);\n",
    "ax3.set_title('Annotated Top down binary', fontsize=30);\n",
    "ax4.imshow(detector._original_annotated_image);\n",
    "ax4.set_title('Annotated Undistorted image', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = LaneDetector(dist_pickle['mtx'], dist_pickle['dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_images/test2.jpg')\n",
    "\n",
    "detector.process_image(image)\n",
    "\n",
    "# Visualize\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20,10));\n",
    "ax1.imshow(detector._undistorted_image);\n",
    "ax1.set_title('Undistorted Image', fontsize=30);\n",
    "ax2.imshow(detector._top_down_binary_image, cmap='gray');\n",
    "ax2.set_title('Top down binary', fontsize=30);\n",
    "ax3.imshow(detector._top_down_binary_with_lines_image);\n",
    "ax3.set_title('Annotated Top down binary', fontsize=30);\n",
    "ax4.imshow(detector._original_annotated_image);\n",
    "ax4.set_title('Annotated Undistorted image', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = LaneDetector(dist_pickle['mtx'], dist_pickle['dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_images/test3.jpg')\n",
    "\n",
    "detector.process_image(image)\n",
    "\n",
    "# Visualize\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20,10));\n",
    "ax1.imshow(detector._undistorted_image);\n",
    "ax1.set_title('Undistorted Image', fontsize=30);\n",
    "ax2.imshow(detector._top_down_binary_image, cmap='gray');\n",
    "ax2.set_title('Top down binary', fontsize=30);\n",
    "ax3.imshow(detector._top_down_binary_with_lines_image);\n",
    "ax3.set_title('Annotated Top down binary', fontsize=30);\n",
    "ax4.imshow(detector._original_annotated_image);\n",
    "ax4.set_title('Annotated Undistorted image', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = LaneDetector(dist_pickle['mtx'], dist_pickle['dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_images/test4.jpg')\n",
    "\n",
    "detector.process_image(image)\n",
    "\n",
    "# Visualize\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20,10));\n",
    "ax1.imshow(detector._undistorted_image);\n",
    "ax1.set_title('Undistorted Image', fontsize=30);\n",
    "ax2.imshow(detector._top_down_binary_image, cmap='gray');\n",
    "ax2.set_title('Top down binary', fontsize=30);\n",
    "ax3.imshow(detector._top_down_binary_with_lines_image);\n",
    "ax3.set_title('Annotated Top down binary', fontsize=30);\n",
    "ax4.imshow(detector._original_annotated_image);\n",
    "ax4.set_title('Annotated Undistorted image', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = LaneDetector(dist_pickle['mtx'], dist_pickle['dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_images/test5.jpg')\n",
    "\n",
    "detector.process_image(image)\n",
    "\n",
    "# Visualize\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20,10));\n",
    "ax1.imshow(detector._undistorted_image);\n",
    "ax1.set_title('Undistorted Image', fontsize=30);\n",
    "ax2.imshow(detector._top_down_binary_image, cmap='gray');\n",
    "ax2.set_title('Top down binary', fontsize=30);\n",
    "ax3.imshow(detector._top_down_binary_with_lines_image);\n",
    "ax3.set_title('Annotated Top down binary', fontsize=30);\n",
    "ax4.imshow(detector._original_annotated_image);\n",
    "ax4.set_title('Annotated Undistorted image', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(detector._lline._histogram_allx[-1], detector._rline._histogram_allx[-1])\n",
    "print(detector._lline._y_deriv, detector._rline._y_deriv)\n",
    "print(detector._rline._line_pos_m - detector._lline._line_pos_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = LaneDetector(dist_pickle['mtx'], dist_pickle['dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_images/test6.jpg')\n",
    "\n",
    "detector.process_image(image)\n",
    "\n",
    "# Visualize\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20,10));\n",
    "ax1.imshow(detector._undistorted_image);\n",
    "ax1.set_title('Undistorted Image', fontsize=30);\n",
    "ax2.imshow(detector._top_down_binary_image, cmap='gray');\n",
    "ax2.set_title('Top down binary', fontsize=30);\n",
    "ax3.imshow(detector._top_down_binary_with_lines_image);\n",
    "ax3.set_title('Annotated Top down binary', fontsize=30);\n",
    "ax4.imshow(detector._original_annotated_image);\n",
    "ax4.set_title('Annotated Undistorted image', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Once you have implemented a successful pipeline on the test images,\n",
    "# you will run your algorithm on a video. \n",
    "# In the case of the video, you must search for the lane lines in the first few frames, and, \n",
    "# once you have a high-confidence detection, \n",
    "# use that information to track the position and curvature of the lines from frame to frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = LaneDetector(dist_pickle['mtx'], dist_pickle['dist'])\n",
    "input_clip = VideoFileClip(\"project_video.mp4\")\n",
    "annotated_output = 'project_video_annotated.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotated_clip = input_clip.fl_image(detector.process_image) #NOTE: this function expects color images!!\n",
    "%time annotated_clip.write_videofile(annotated_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(annotated_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_clip = VideoFileClip(\"challenge_video.mp4\")\n",
    "annotated_output = 'challenge_video_annotated.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detector = LaneDetector(dist_pickle['mtx'], dist_pickle['dist'])\n",
    "annotated_clip = input_clip.fl_image(detector.process_image) #NOTE: this function expects color images!!\n",
    "%time annotated_clip.write_videofile(annotated_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(annotated_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_clip = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "annotated_output = 'harder_challenge_video_annotated.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detector = LaneDetector(dist_pickle['mtx'], dist_pickle['dist'])\n",
    "annotated_clip = input_clip.fl_image(detector.process_image) #NOTE: this function expects color images!!\n",
    "%time annotated_clip.write_videofile(annotated_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(annotated_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
